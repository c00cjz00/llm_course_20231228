{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5070051-c2bb-4f65-a4a5-b9fa10a522b5",
   "metadata": {},
   "source": [
    "## vLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b38d9-fb5d-499c-8748-0a95c9b99032",
   "metadata": {},
   "source": [
    "## 初始環境設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82eeeb-58da-434a-83c2-9461b6cdc32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin'\n",
    "os.environ['PATH']=os.environ['PATH']+':'+Add_Binarry_Path\n",
    "current_foldr=!pwd\n",
    "current_foldr=current_foldr[0]\n",
    "current_foldr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079679b-522b-49b1-a092-703ffae8daec",
   "metadata": {},
   "source": [
    "## 安裝套件\n",
    "安裝完成後建議, 點選上方選單, 直接階段->重新啟動工作階段, 確保 library重置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb2c11-f903-4546-8b05-e7b3bfead5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install https://github.com/vllm-project/vllm/releases/download/v0.3.0/vllm-0.3.0+cu118-cp310-cp310-manylinux1_x86_64.whl -q\n",
    "!pip install --upgrade xformers==0.0.23.post1 torch==2.1.2 --index-url https://download.pytorch.org/whl/cu118 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f160880-037a-4adc-99af-19e27a31cafc",
   "metadata": {},
   "source": [
    "## 確認CUDA版本, 以及否能使用GPU\n",
    "若無gpu 請點選右側->已連線->變更執行階段類型->T4 Gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b55201-6099-443c-9dd1-8091e5c3bc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "print(torch.__version__)  #注意是双下划线\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3568d017-96b2-4669-aedf-319f78dad160",
   "metadata": {},
   "source": [
    "## MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a611fec-fdbf-478d-bd67-3c8db7eae6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.executable=\"/usr/bin/python3.10\"\n",
    "#!{sys.executable} -V\n",
    "\n",
    "#from pprint import pprint\n",
    "#pprint(sys.path)\n",
    "#sys.path.append(’需要引用模块的地址')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35de45-97dd-44be-8774-04aabd08d78c",
   "metadata": {},
   "source": [
    "###　Model Vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e6b692-99aa-41af-9d08-105f2e08f5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 -m vllm.entrypoints.api_server \\\n",
    "    --model /work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf --swap-space 16 \\\n",
    "    --disable-log-requests --host 0.0.0.0 --port 8080 --max-num-seqs 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25b7e5-b0dd-4159-84dd-2f8ee0e6bd84",
   "metadata": {},
   "source": [
    "##　Model Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05100f5d-531c-4947-afc6-b3c4cd613cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 -m vllm.entrypoints.openai.api_server \\\n",
    "--model /work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf --swap-space 16 \\\n",
    "--disable-log-requests --host 0.0.0.0 --port 5001 --max-num-seqs 20 --served-model-name llama-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93804d-7168-4f78-918c-98c19cec4929",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3d60d-0362-469e-8ebd-2b416da8d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://gpn3001:5001/v1/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6590b-022c-4e86-93a6-f77a0f3d5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl http://gpn3001:5001/v1/completions \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "\"model\": \"llama-2\",\n",
    "\"prompt\": \"San Francisco is a\",\n",
    "\"max_tokens\": 70,\n",
    "\"temperature\": 0\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17013510-5015-4772-bc5a-69c6b176be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl http://gpn3001:5001/v1/chat/completions \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "\"model\": \"llama-2\",\n",
    "\"messages\": [\n",
    "{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "{\"role\": \"user\", \"content\": \"什麼是聯邦式學習?\"}\n",
    "]\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9d0e1-5cd1-4452-9556-1a50fa0f42d0",
   "metadata": {},
   "source": [
    "## Singularity　Model Openai\n",
    "change kernel to Pytohn 3 (ipykernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98261ae-73b6-4c99-b5a7-c0677bd6fd0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!/work/opt/ohpc/Taiwania3/libs/singularity/3.10.2/bin/singularity exec --nv -C \\\n",
    "-B /work -B /work/u00cjz00/os/ubuntu/bin:/usr/ubuntu_bin \\\n",
    "-B /work/g00cjz00/libraryFolder/P-3.10-work-genai_cuda_11.8.0-cudnn8-runtime-ubuntu22.04/local/lib:/home/g00cjz00/.local/lib \\\n",
    "-B /work/g00cjz00/libraryFolder/P-3.10-work-genai_cuda_11.8.0-cudnn8-runtime-ubuntu22.04/local/bin:/home/g00cjz00/.local/bin \\\n",
    "/work/u00cjz00/nvidia/cuda_11.8.0-cudnn8-runtime-ubuntu22.04.sif \\\n",
    "bash -c 'export PATH=$PATH:$HOME/.local/bin; \\\n",
    "python3 -m vllm.entrypoints.openai.api_server \\\n",
    "--model /work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf --swap-space 16 \\\n",
    "--disable-log-requests --host 0.0.0.0 --port 5001 --max-num-seqs 20 --served-model-name llama-2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26846bb-8b36-4707-9925-3a22615c728f",
   "metadata": {},
   "source": [
    "## SLURM SingularityModel Openai\n",
    "change kernel to Pytohn 3 (ipykernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b966d-5fd2-4ee2-be51-de1dd0254611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << \\EOF >  demo.slurm\n",
    "#!/work/u00cjz00/binary/bash5.0/bin/bash\n",
    "#SBATCH -A GOV109189                                                    ### project number, Example MST109178\n",
    "#SBATCH -J _t2vllm_                                                     ### Job name, Exmaple jupyterlab\n",
    "#SBATCH -p gp4d                                                         ### Partition Name, Example ngs1gpu\n",
    "#SBATCH --nodes=1                                                       ### Nodes, Default 1, node number\n",
    "#SBATCH --ntasks-per-node=1                                             ### Tasks, Default 1, per node tasks\n",
    "#SBATCH -c 4                                                            ### Cores assigned to each task, Example 4\n",
    "#SBATCH --gres=gpu:1                                                    ### GPU number, Example gpu:1\n",
    "#SBATCH --time=0-1:00:00                                                ### Runnung time, days-hours:minutes:seconds or hours:minutes:seconds\n",
    "#SBATCH -o genai_%j.out                                                 ### Log folder, Here %j is job ID\n",
    "#SBATCH -e genai_%j.err                                                 ### Log folder, Here %j is job ID\n",
    "\n",
    "/work/opt/ohpc/Taiwania3/libs/singularity/3.10.2/bin/singularity exec --nv -C \\\n",
    "-B /work -B /work/u00cjz00/os/ubuntu/bin:/usr/ubuntu_bin \\\n",
    "-B /work/g00cjz00/libraryFolder/P-3.10-work-genai_cuda_11.8.0-cudnn8-runtime-ubuntu22.04/local/lib:/home/g00cjz00/.local/lib \\\n",
    "-B /work/g00cjz00/libraryFolder/P-3.10-work-genai_cuda_11.8.0-cudnn8-runtime-ubuntu22.04/local/bin:/home/g00cjz00/.local/bin \\\n",
    "/work/u00cjz00/nvidia/cuda_11.8.0-cudnn8-runtime-ubuntu22.04.sif \\\n",
    "bash -c 'export PATH=$PATH:$HOME/.local/bin; \\\n",
    "python3 -m vllm.entrypoints.openai.api_server \\\n",
    "--model /work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf --swap-space 16 \\\n",
    "--disable-log-requests --host 0.0.0.0 --port 5001 --max-num-seqs 20 --served-model-name llama-2'\n",
    "\n",
    "EOF\n",
    "\n",
    "sbatch  demo.slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3764136c-6428-45d7-ad0d-17c8e9bd49bd",
   "metadata": {},
   "source": [
    "## CHECK SLURM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f3f4cf-cac9-407d-9b4f-83ed3c2fd185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!squeue -u $(whoami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6cd6fd-a79f-4465-8333-04cd1668e932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat genai_569512.out\n",
    "!cat genai_569512.err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971eef2-d769-4eaa-8079-8b0c5af52dfc",
   "metadata": {},
   "source": [
    "## CURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05577de-b515-460f-9ea0-8c3164307033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl http://gn0901:5001/v1/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf5cc7-5a0e-4cd9-ae73-d7df62bd0467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl http://gn0901:5001/v1/completions \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "\"model\": \"llama-2\",\n",
    "\"prompt\": \"San Francisco is a\",\n",
    "\"max_tokens\": 70,\n",
    "\"temperature\": 0\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f066b7-796f-44d1-b88c-95c000bc4396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl http://gn0901:5001/v1/chat/completions \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "\"model\": \"llama-2\",\n",
    "\"messages\": [\n",
    "{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "{\"role\": \"user\", \"content\": \"什麼是聯邦式學習?\"}\n",
    "]\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d49ce-9d82-4a08-9368-9d28feb98286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
